{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data loaded into database: data/electricity.db\n"
     ]
    }
   ],
   "source": [
    "# Data_Ingestion\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "\n",
    "# Paths for the CSV file and database\n",
    "FILE_NAME = \"data/electricity_prices.csv\"\n",
    "DATABASE_NAME = \"data/electricity.db\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_data_to_db(csv_file, db_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    engine = create_engine(f'sqlite:///{db_file}')\n",
    "    df.to_sql('electricity', con=engine, if_exists='replace', index=False)\n",
    "    logging.info(f\"Data loaded into database: {db_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_data_to_db(FILE_NAME, DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_db(db_file):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    sql_query = \"SELECT * FROM electricity\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    conn.close()  # Ensure the connection is closed after reading the data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:visions.backends:Pandas backend loaded 2.2.2\n",
      "INFO:visions.backends:Numpy backend loaded 1.26.4\n",
      "INFO:visions.backends:Pyspark backend NOT loaded\n",
      "INFO:visions.backends:Python backend loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7c748576ef425ca4e90ec6a37fae21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c540746db1c1417695618ee7ee9f4476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd6f1107cc34d89a14306908feca90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023ee416713d47f78f513d165eef6f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:EDA report generated\n"
     ]
    }
   ],
   "source": [
    "# Eda\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from ydata_profiling import ProfileReport\n",
    "import logging\n",
    "DATABASE_NAME = \"data/electricity.db\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def perform_eda(df):\n",
    "    os.makedirs('reports', exist_ok=True)\n",
    "    profile = ProfileReport(df, title=\"Electricity Price Data Profiling Report\", correlations={\"auto\": {\"calculate\": False}})\n",
    "    profile.to_file(\"reports/electricity_price_profile.html\")\n",
    "    logging.info(\"EDA report generated\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    perform_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/01 11:42:33 INFO mlflow.tracking.fluent: Experiment with name 'Electricity Price Prediction' does not exist. Creating a new experiment.\n",
      "INFO:root:Linear Regression model logged to MLflow\n",
      "INFO:root:Random Forest model logged to MLflow\n",
      "INFO:root:Elastic Net model logged to MLflow\n",
      "INFO:root:Gradient Boosting model logged to MLflow\n",
      "INFO:root:Best model: Random Forest with RMSE: 21.655789236118906\n",
      "Successfully registered model 'ElectricityPriceModel'.\n",
      "2024/08/01 11:46:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ElectricityPriceModel, version 1\n",
      "Created version '1' of model 'ElectricityPriceModel'.\n",
      "INFO:root:Random Forest model registered in MLflow Model Registry\n",
      "INFO:root:Random Forest model and preprocessor saved locally\n"
     ]
    }
   ],
   "source": [
    "# Model_Training\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "DATABASE_NAME = \"data/electricity.db\"\n",
    "\n",
    "def create_preprocessor(numerical_features, categorical_features):\n",
    "    numerical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, preprocessor):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    return name, rmse_scores.mean(), model\n",
    "\n",
    "def evaluate_models(X_train, y_train, preprocessor):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"Elastic Net\": ElasticNet(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(evaluate_model)(name, model, X_train, y_train, preprocessor) \n",
    "        for name, model in models.items()\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def log_model_to_mlflow(model, model_name, X_train, X_test, y_train, y_test, preprocessor):\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    mlflow.set_experiment(\"Electricity Price Prediction\")\n",
    "\n",
    "    # Accessing MLflow credentials\n",
    "    username = os.environ['MLFLOW_TRACKING_USERNAME']\n",
    "    password = os.environ['MLFLOW_TRACKING_PASSWORD']\n",
    "    session = requests.Session()\n",
    "    session.auth = (username, password)\n",
    "\n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.1,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\", \"POST\", \"PUT\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        logging.info(f\"{model_name} model logged to MLflow\")\n",
    "\n",
    "        return run.info.run_id, rmse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    \n",
    "    numerical_features = ['DayOfWeek', 'WeekOfYear', 'Day', 'Month', 'Year', 'PeriodOfDay',\n",
    "                          'ForecastWindProduction', 'SystemLoadEA', 'SMPEA', 'ORKTemperature',\n",
    "                          'ORKWindspeed', 'CO2Intensity', 'ActualWindProduction', 'SystemLoadEP2']\n",
    "    categorical_features = ['Holiday']\n",
    "    \n",
    "    X = df.drop('SMPEP2', axis=1)\n",
    "    y = df['SMPEP2']\n",
    "\n",
    "    # Drop rows where the target variable is NaN\n",
    "    X = X[~y.isna()]\n",
    "    y = y.dropna()\n",
    "\n",
    "    preprocessor = create_preprocessor(numerical_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    models_results = evaluate_models(X_train, y_train, preprocessor)\n",
    "\n",
    "    best_model_name = None\n",
    "    best_rmse = float('inf')\n",
    "    best_run_id = None\n",
    "    best_model = None\n",
    "\n",
    "    for model_name, rmse, model in models_results:\n",
    "        run_id, model_rmse = log_model_to_mlflow(model, model_name, X_train, X_test, y_train, y_test, preprocessor)\n",
    "        if model_rmse < best_rmse:\n",
    "            best_rmse = model_rmse\n",
    "            best_model_name = model_name\n",
    "            best_run_id = run_id\n",
    "            best_model = model\n",
    "\n",
    "    logging.info(f\"Best model: {best_model_name} with RMSE: {best_rmse}\")\n",
    "\n",
    "    # Register the best model\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{best_run_id}/model\",\n",
    "        name=\"ElectricityPriceModel\"\n",
    "    )\n",
    "    logging.info(f\"{best_model_name} model registered in MLflow Model Registry\")\n",
    "\n",
    "    # Save the best model and preprocessor locally\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', best_model)\n",
    "    ])\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    joblib.dump(pipeline, 'model/best_model.pkl')\n",
    "    logging.info(f\"{best_model_name} model and preprocessor saved locally\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Optimized model parameters: {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "INFO:root:Best RMSE score: 22.770299435556765\n",
      "INFO:root:Random Forest model logged to MLflow\n",
      "INFO:root:Best optimized model: Random Forest with RMSE: 22.770299435556765\n",
      "Successfully registered model 'OptimizedElectricityPriceModel'.\n",
      "2024/08/01 12:04:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: OptimizedElectricityPriceModel, version 1\n",
      "Created version '1' of model 'OptimizedElectricityPriceModel'.\n",
      "INFO:root:Optimized Random Forest model registered in MLflow Model Registry\n",
      "INFO:root:Optimized Random Forest model and preprocessor saved locally\n"
     ]
    }
   ],
   "source": [
    "# Model_Optimization\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import logging\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "DATABASE_NAME = \"data/electricity.db\"\n",
    "\n",
    "def create_preprocessor(numerical_features, categorical_features):\n",
    "    numerical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def optimize_model(model, param_grid, X_train, y_train, preprocessor):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "    return best_pipeline, best_params, best_score\n",
    "\n",
    "def log_and_register_model_to_mlflow(pipeline, model_name, X_train, X_test, y_train, y_test):\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    mlflow.set_experiment(\"Electricity Price Prediction\")\n",
    "\n",
    "    # Accessing MLflow credentials\n",
    "    username = os.environ['MLFLOW_TRACKING_USERNAME']\n",
    "    password = os.environ['MLFLOW_TRACKING_PASSWORD']\n",
    "    session = requests.Session()\n",
    "    session.auth = (username, password)\n",
    "\n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.1,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\", \"POST\", \"PUT\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_params(pipeline.named_steps['model'].get_params())\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        logging.info(f\"{model_name} model logged to MLflow\")\n",
    "\n",
    "        return run.info.run_id, rmse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    \n",
    "    numerical_features = ['DayOfWeek', 'WeekOfYear', 'Day', 'Month', 'Year', 'PeriodOfDay',\n",
    "                          'ForecastWindProduction', 'SystemLoadEA', 'SMPEA', 'ORKTemperature',\n",
    "                          'ORKWindspeed', 'CO2Intensity', 'ActualWindProduction', 'SystemLoadEP2']\n",
    "    categorical_features = ['Holiday']\n",
    "    \n",
    "    X = df.drop('SMPEP2', axis=1)\n",
    "    y = df['SMPEP2']\n",
    "\n",
    "    # Drop rows where the target variable is NaN\n",
    "    X = X[~y.isna()]\n",
    "    y = y.dropna()\n",
    "\n",
    "    preprocessor = create_preprocessor(numerical_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Load the best model name from the training script\n",
    "    best_model_name = \"Random Forest\"  # Example: You should load this dynamically based on your previous script\n",
    "\n",
    "    if best_model_name == \"Linear Regression\":\n",
    "        best_model = LinearRegression()\n",
    "        param_grid = {\n",
    "            'model__fit_intercept': [True, False],\n",
    "            'model__normalize': [True, False]\n",
    "        }\n",
    "    elif best_model_name == \"Random Forest\":\n",
    "        best_model = RandomForestRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [10, 20],\n",
    "            'model__min_samples_split': [2, 5]\n",
    "        }\n",
    "    elif best_model_name == \"Elastic Net\":\n",
    "        best_model = ElasticNet(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__alpha': [0.1, 1.0],\n",
    "            'model__l1_ratio': [0.1, 0.5]\n",
    "        }\n",
    "    elif best_model_name == \"Gradient Boosting\":\n",
    "        best_model = GradientBoostingRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__learning_rate': [0.01, 0.1],\n",
    "            'model__max_depth': [3, 5]\n",
    "        }\n",
    "\n",
    "    optimized_pipeline, best_params, best_score = optimize_model(best_model, param_grid, X_train, y_train, preprocessor)\n",
    "    logging.info(f\"Optimized model parameters: {best_params}\")\n",
    "    logging.info(f\"Best RMSE score: {best_score}\")\n",
    "\n",
    "    run_id, rmse = log_and_register_model_to_mlflow(optimized_pipeline, best_model_name, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    logging.info(f\"Best optimized model: {best_model_name} with RMSE: {best_score}\")\n",
    "\n",
    "    # Register the best optimized model\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",\n",
    "        name=\"OptimizedElectricityPriceModel\"\n",
    "    )\n",
    "    logging.info(f\"Optimized {best_model_name} model registered in MLflow Model Registry\")\n",
    "\n",
    "    # Save the optimized model and preprocessor locally\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    joblib.dump(optimized_pipeline, 'model/optimized_model.pkl')\n",
    "    logging.info(f\"Optimized {best_model_name} model and preprocessor saved locally\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
