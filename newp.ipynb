{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Connected to SQLite database: C:/UB/Sem_1/newp/data/electricity.db\n",
      "Data loaded into database: C:/UB/Sem_1/newp/data/electricity.db\n"
     ]
    }
   ],
   "source": [
    "# data_ingestion.py\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Paths for the CSV file and database\n",
    "FILE_NAME = \"C:/UB/Sem_1/newp/data/electricity_prices.csv\"\n",
    "DATABASE_NAME = \"C:/UB/Sem_1/newp/data/electricity.db\"\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(f\"Successfully Connected to SQLite database: {db_file}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "def load_data_to_db(csv_file, db_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    engine = create_engine(f'sqlite:///{db_file}')\n",
    "    df.to_sql('electricity', con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Data loaded into database: {db_file}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conn = create_connection(DATABASE_NAME)\n",
    "    df = load_data_to_db(FILE_NAME, DATABASE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8fa2b892454a49b39015157a93a353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'Christmas Eve'')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a567cd93394431aa8823021725dfee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14479f744b094cb0b61dcc43e6c045fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777735784298479c992e0d37851f458c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA report generated\n"
     ]
    }
   ],
   "source": [
    "# eda.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "DATABASE_NAME = \"C:/UB/Sem_1/newp/data/electricity.db\"\n",
    "\n",
    "def load_data_from_db(db_file):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    sql_query = \"SELECT * FROM electricity\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    return df\n",
    "\n",
    "def perform_eda(df):\n",
    "    # Ensure the 'reports' directory exists\n",
    "    if not os.path.exists('reports'):\n",
    "        os.makedirs('reports')\n",
    "    \n",
    "    profile = ProfileReport(df, title=\"Electricity Price Data Profiling Report\")\n",
    "    profile.to_file(\"reports/electricity_price_profile.html\")\n",
    "    print(\"EDA report generated\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    perform_eda(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting model logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "# model_training.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "DATABASE_NAME = \"C:/UB/Sem_1/newp/data/electricity.db\"\n",
    "\n",
    "def load_data_from_db(db_file):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    sql_query = \"SELECT * FROM electricity\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    return df\n",
    "\n",
    "def create_preprocessor(numerical_features, categorical_features):\n",
    "    numerical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def evaluate_models(X_train, y_train):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"Elastic Net\": ElasticNet(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        rmse_scores = (-scores) ** 0.5\n",
    "        results[name] = rmse_scores.mean()\n",
    "    \n",
    "    top_models = sorted(results.items(), key=lambda x: x[1])[:3]\n",
    "    return top_models\n",
    "\n",
    "def log_baseline_model_to_mlflow(model, model_name, X_train, X_test, y_train, y_test, preprocessor):\n",
    "    os.environ['MLFLOW_TRACKING_URI'] = \"https://dagshub.com/praneeth-bojanala5/newp.mlflow\"\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME'] = 'praneeth-bojanala5'\n",
    "    os.environ['MLFLOW_TRACKING_PASSWORD'] = '15ca78d80ad1494f59c42142b650fcd36df60e03'\n",
    "\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    mlflow.set_experiment(\"Electricity Price Regression\")\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        print(f\"{model_name} model logged to MLflow\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    \n",
    "    numerical_features = ['DayOfWeek', 'WeekOfYear', 'Day', 'Month', 'Year', 'PeriodOfDay',\n",
    "                          'ForecastWindProduction', 'SystemLoadEA', 'SMPEA', 'ORKTemperature',\n",
    "                          'ORKWindspeed', 'CO2Intensity', 'ActualWindProduction', 'SystemLoadEP2']\n",
    "    categorical_features = ['Holiday']\n",
    "    \n",
    "    X = df.drop('SMPEP2', axis=1)\n",
    "    y = df['SMPEP2']\n",
    "\n",
    "    # Drop rows where the target variable is NaN\n",
    "    X = X[~y.isna()]\n",
    "    y = y.dropna()\n",
    "\n",
    "    preprocessor = create_preprocessor(numerical_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    top_models = evaluate_models(X_train, y_train)\n",
    "\n",
    "    for model_name, _ in top_models:\n",
    "        if model_name == \"Linear Regression\":\n",
    "            model = LinearRegression()\n",
    "        elif model_name == \"Random Forest\":\n",
    "            model = RandomForestRegressor(random_state=42)\n",
    "        elif model_name == \"Elastic Net\":\n",
    "            model = ElasticNet(random_state=42)\n",
    "        elif model_name == \"Gradient Boosting\":\n",
    "            model = GradientBoostingRegressor(random_state=42)\n",
    "        \n",
    "        log_baseline_model_to_mlflow(model, model_name, X_train, X_test, y_train, y_test, preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized MAE for Linear Regression: 14.221703910761253\n",
      "Optimized MSE for Linear Regression: 679.1293278363725\n",
      "Optimized RMSE for Linear Regression: 26.06010989685908\n",
      "Linear Regression model logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized MAE for Random Forest: 14.194454538634176\n",
      "Optimized MSE for Random Forest: 644.5406516073597\n",
      "Optimized RMSE for Random Forest: 25.38780517507096\n",
      "Random Forest model logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized MAE for Elastic Net: 14.207558707941423\n",
      "Optimized MSE for Elastic Net: 678.5357676649829\n",
      "Optimized RMSE for Elastic Net: 26.048719117549386\n",
      "Elastic Net model logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bunny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized MAE for Gradient Boosting: 12.650449805101104\n",
      "Optimized MSE for Gradient Boosting: 567.2546689677753\n",
      "Optimized RMSE for Gradient Boosting: 23.817108744929037\n",
      "Gradient Boosting model logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "# model_optimization.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "DATABASE_NAME = \"C:/UB/Sem_1/newp/data/electricity.db\"\n",
    "\n",
    "def load_data_from_db(db_file):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    sql_query = \"SELECT * FROM electricity\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    return df\n",
    "\n",
    "def create_preprocessor(numerical_features, categorical_features):\n",
    "    numerical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def optimize_model(df, model, param_dist, model_name):\n",
    "    numerical_features = ['DayOfWeek', 'WeekOfYear', 'Day', 'Month', 'Year', 'PeriodOfDay',\n",
    "                          'ForecastWindProduction', 'SystemLoadEA', 'SMPEA', 'ORKTemperature',\n",
    "                          'ORKWindspeed', 'CO2Intensity', 'ActualWindProduction', 'SystemLoadEP2']\n",
    "    categorical_features = ['Holiday']\n",
    "    \n",
    "    X = df.drop('SMPEP2', axis=1)\n",
    "    y = df['SMPEP2']\n",
    "\n",
    "    # Drop rows where the target variable is NaN\n",
    "    X = X[~y.isna()]\n",
    "    y = y.dropna()\n",
    "\n",
    "    preprocessor = create_preprocessor(numerical_features, categorical_features)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=10, cv=3, random_state=42, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    print(f\"Optimized MAE for {model_name}: {mae}\")\n",
    "    print(f\"Optimized MSE for {model_name}: {mse}\")\n",
    "    print(f\"Optimized RMSE for {model_name}: {rmse}\")\n",
    "\n",
    "    return best_model, mae, mse, rmse\n",
    "\n",
    "def log_optimized_model_to_mlflow(model, model_name, mae, mse, rmse):\n",
    "    os.environ['MLFLOW_TRACKING_URI'] = \"https://dagshub.com/praneeth-bojanala5/newp.mlflow\"\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME'] = 'praneeth-bojanala5'\n",
    "    os.environ['MLFLOW_TRACKING_PASSWORD'] = '15ca78d80ad1494f59c42142b650fcd36df60e03'\n",
    "\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    mlflow.set_experiment(\"Electricity Price Regression\")\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(f\"{model_name} model logged to MLflow\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data_from_db(DATABASE_NAME)\n",
    "    \n",
    "    # Define parameter grids for the top 3 models\n",
    "    param_dist_lr = {\n",
    "        'model__fit_intercept': [True, False]\n",
    "    }\n",
    "    param_dist_rf = {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_features': ['sqrt', 'log2'],\n",
    "        'model__max_depth': [4, 5],\n",
    "        'model__criterion': ['squared_error', 'absolute_error']\n",
    "    }\n",
    "    param_dist_en = {\n",
    "        'model__alpha': np.logspace(-4, 0, 10),\n",
    "        'model__l1_ratio': np.linspace(0, 1, 5)\n",
    "    }\n",
    "    param_dist_gb = {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__max_depth': [3, 4]\n",
    "    }\n",
    "\n",
    "    # Linear Regression\n",
    "    model_lr, mae_lr, mse_lr, rmse_lr = optimize_model(df, LinearRegression(), param_dist_lr, \"Linear Regression\")\n",
    "    log_optimized_model_to_mlflow(model_lr, \"Linear Regression\", mae_lr, mse_lr, rmse_lr)\n",
    "\n",
    "    # Random Forest\n",
    "    model_rf, mae_rf, mse_rf, rmse_rf = optimize_model(df, RandomForestRegressor(random_state=42), param_dist_rf, \"Random Forest\")\n",
    "    log_optimized_model_to_mlflow(model_rf, \"Random Forest\", mae_rf, mse_rf, rmse_rf)\n",
    "\n",
    "    # Elastic Net\n",
    "    model_en, mae_en, mse_en, rmse_en = optimize_model(df, ElasticNet(random_state=42), param_dist_en, \"Elastic Net\")\n",
    "    log_optimized_model_to_mlflow(model_en, \"Elastic Net\", mae_en, mse_en, rmse_en)\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    model_gb, mae_gb, mse_gb, rmse_gb = optimize_model(df, GradientBoostingRegressor(random_state=42), param_dist_gb, \"Gradient Boosting\")\n",
    "    log_optimized_model_to_mlflow(model_gb, \"Gradient Boosting\", mae_gb, mse_gb, rmse_gb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
